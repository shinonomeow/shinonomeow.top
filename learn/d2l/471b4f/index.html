<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.163" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"循环神经网络","image":[""],"dateModified":"2025-01-27T11:13:57.000Z","author":[]}</script><meta property="og:url" content="https://shinonomeow.top/learn/d2l/471b4f/"><meta property="og:site_name" content="東雲研究所"><meta property="og:title" content="循环神经网络"><meta property="og:description" content="开始了文本方向的神经网络，之前的卷积看完还是很不知所云的， 对于为什么这样会更好还是只有一个大概的解释，估计文本这方面也不遑多让吧。 I have started learing language Models, but I'm still confused after studying Convolutional Neural Networks. T..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-01-27T11:13:57.000Z"><meta property="article:tag" content="RNN"><meta property="article:modified_time" content="2025-01-27T11:13:57.000Z"><link rel="icon" type="image/png" href="/favicon.ico"><title>循环神经网络 | 東雲研究所</title><meta name="description" content="开始了文本方向的神经网络，之前的卷积看完还是很不知所云的， 对于为什么这样会更好还是只有一个大概的解释，估计文本这方面也不遑多让吧。 I have started learing language Models, but I'm still confused after studying Convolutional Neural Networks. T..."><link rel="preload" href="/assets/style-DITZBIEq.css" as="style"><link rel="stylesheet" href="/assets/style-DITZBIEq.css"><link rel="modulepreload" href="/assets/app-CN1iVX_s.js"><link rel="modulepreload" href="/assets/index.html-DWX5JnI8.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-701fc3ad><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-58dee1a3></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-58dee1a3> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-701fc3ad data-v-b4c65a14><div class="vp-navbar" vp-navbar data-v-b4c65a14 data-v-16cfc126><div class="wrapper" data-v-16cfc126><div class="container" data-v-16cfc126><div class="title" data-v-16cfc126><div class="vp-navbar-title" data-v-16cfc126 data-v-489260e5><a class="vp-link link no-icon title" href="/" data-v-489260e5><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="/images/sakamoto.png" alt data-v-ffbb3aae><!--]--><!--[--><img class="vp-image light logo" style="" src="/images/sakamoto.png" alt data-v-ffbb3aae><!--]--><!--]--><!--]--><span data-v-489260e5>東雲研究所</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-16cfc126><div class="content-body" data-v-16cfc126><!--[--><!--]--><div class="vp-navbar-search search" data-v-16cfc126><div class="search-wrapper" data-v-7d054f7e><!----><div id="local-search" data-v-7d054f7e><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-7d054f7e><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-16cfc126 data-v-4fd4e0ae><span id="main-nav-aria-label" class="visually-hidden" data-v-4fd4e0ae>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/blog/" tabindex="0" data-v-4fd4e0ae data-v-a1174a9a><!--[--><!----><span data-v-a1174a9a>博客</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/speak/" tabindex="0" data-v-4fd4e0ae data-v-a1174a9a><!--[--><!----><span data-v-a1174a9a>随笔</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-4fd4e0ae data-v-88076b89><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-88076b89><span class="text" data-v-88076b89><!----><!----><span data-v-88076b89>笔记</span><!----><span class="vpi-chevron-down text-icon" data-v-88076b89></span></span></button><div class="menu" data-v-88076b89><div class="vp-menu" data-v-88076b89 data-v-a539c55b><div class="items" data-v-a539c55b><!--[--><!--[--><div class="vp-menu-link" data-v-a539c55b data-v-1923018c><a class="vp-link link" href="/lazyvim/" data-v-1923018c><!--[--><!----> LazyVim <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/blog/archives/" tabindex="0" data-v-4fd4e0ae data-v-a1174a9a><!--[--><!----><span data-v-a1174a9a>归档</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-4fd4e0ae data-v-88076b89><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-88076b89><span class="text" data-v-88076b89><!----><!----><span data-v-88076b89>更多</span><!----><span class="vpi-chevron-down text-icon" data-v-88076b89></span></span></button><div class="menu" data-v-88076b89><div class="vp-menu" data-v-88076b89 data-v-a539c55b><div class="items" data-v-a539c55b><!--[--><!--[--><div class="vp-menu-link" data-v-a539c55b data-v-1923018c><a class="vp-link link" href="/friend/" data-v-1923018c><!--[--><!----> 友情链接 <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-a539c55b data-v-1923018c><a class="vp-link link" href="/about/" data-v-1923018c><!--[--><!----> 关于我 <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!--[--><!--]--><div class="vp-flyout vp-navbar-translations translations" data-v-16cfc126 data-v-d10a16ab data-v-88076b89><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="选择语言" data-v-88076b89><span class="text" data-v-88076b89><!----><span class="vpi-languages option-icon" data-v-88076b89></span><!----><!----><span class="vpi-chevron-down text-icon" data-v-88076b89></span></span></button><div class="menu" data-v-88076b89><div class="vp-menu" data-v-88076b89 data-v-a539c55b><!----><!--[--><!--[--><div class="items" data-v-d10a16ab><p class="title" data-v-d10a16ab>简体中文</p><!--[--><div class="vp-menu-link" data-v-d10a16ab data-v-1923018c><a class="vp-link link" href="/en/blog/" data-v-1923018c><!--[--><!----> English <!----><!--]--><!----></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="vp-navbar-appearance appearance" data-v-16cfc126 data-v-55fb85b5><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-55fb85b5 data-v-75dbcb1b data-v-2aaa6b32><span class="check" data-v-2aaa6b32><span class="icon" data-v-2aaa6b32><!--[--><span class="vpi-sun sun" data-v-75dbcb1b></span><span class="vpi-moon moon" data-v-75dbcb1b></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-16cfc126 data-v-08bf8862 data-v-86cf982c><!--[--><a class="vp-social-link no-icon" href="https://github.com/shinonomeow" aria-label="github" target="_blank" rel="noopener" data-v-86cf982c data-v-ce0ec594><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-16cfc126 data-v-f86a1ad3 data-v-88076b89><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-88076b89><span class="vpi-more-horizontal icon" data-v-88076b89></span></button><div class="menu" data-v-88076b89><div class="vp-menu" data-v-88076b89 data-v-a539c55b><!----><!--[--><!--[--><!----><div class="group" data-v-f86a1ad3><div class="item appearance" data-v-f86a1ad3><p class="label" data-v-f86a1ad3>外观</p><div class="appearance-action" data-v-f86a1ad3><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-f86a1ad3 data-v-75dbcb1b data-v-2aaa6b32><span class="check" data-v-2aaa6b32><span class="icon" data-v-2aaa6b32><!--[--><span class="vpi-sun sun" data-v-75dbcb1b></span><span class="vpi-moon moon" data-v-75dbcb1b></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f86a1ad3><div class="item social-links" data-v-f86a1ad3><div class="vp-social-links social-links-list" data-v-f86a1ad3 data-v-86cf982c><!--[--><a class="vp-social-link no-icon" href="https://github.com/shinonomeow" aria-label="github" target="_blank" rel="noopener" data-v-86cf982c data-v-ce0ec594><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-16cfc126 data-v-8ab5430e><span class="container" data-v-8ab5430e><span class="top" data-v-8ab5430e></span><span class="middle" data-v-8ab5430e></span><span class="bottom" data-v-8ab5430e></span></span></button></div></div></div></div><div class="divider" data-v-16cfc126><div class="divider-line" data-v-16cfc126></div></div></div><!----></header><div class="vp-local-nav fixed reached-top is-blog" data-v-701fc3ad data-v-1077497e><button class="hidden menu" disabled aria-expanded="false" aria-controls="SidebarNav" data-v-1077497e><span class="vpi-align-left menu-icon" data-v-1077497e></span><span class="menu-text" data-v-1077497e>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-1077497e data-v-0f05ab24><button data-v-0f05ab24>返回顶部</button><!----></div></div><!----><!--[--><div id="VPContent" vp-content class="vp-content" data-v-701fc3ad data-v-55dec95a><div class="vp-doc-container is-blog" data-v-55dec95a data-v-15ae3a84><!--[--><!--]--><div class="container" data-v-15ae3a84><!----><div class="content" data-v-15ae3a84><div class="content-container" data-v-15ae3a84><!--[--><!--]--><main class="main" data-v-15ae3a84><nav class="vp-breadcrumb" data-v-15ae3a84 data-v-aee51fed><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-aee51fed><!--[--><li property="itemListElement" typeof="ListItem" data-v-aee51fed><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-aee51fed><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-aee51fed></span><meta property="name" content="首页" data-v-aee51fed><meta property="position" content="1" data-v-aee51fed></li><li property="itemListElement" typeof="ListItem" data-v-aee51fed><a class="vp-link link breadcrumb" href="/blog/" property="item" typeof="WebPage" data-v-aee51fed><!--[-->博客<!--]--><!----></a><span class="vpi-chevron-right" data-v-aee51fed></span><meta property="name" content="博客" data-v-aee51fed><meta property="position" content="2" data-v-aee51fed></li><li property="itemListElement" typeof="ListItem" data-v-aee51fed><a class="vp-link link breadcrumb" href="/blog/categories/?id=987a5d" property="item" typeof="WebPage" data-v-aee51fed><!--[-->learning_note<!--]--><!----></a><span class="vpi-chevron-right" data-v-aee51fed></span><meta property="name" content="learning_note" data-v-aee51fed><meta property="position" content="3" data-v-aee51fed></li><li property="itemListElement" typeof="ListItem" data-v-aee51fed><a class="vp-link link breadcrumb" href="/blog/categories/?id=35f7ea" property="item" typeof="WebPage" data-v-aee51fed><!--[-->dive_into_deeplearning<!--]--><!----></a><span class="vpi-chevron-right" data-v-aee51fed></span><meta property="name" content="dive_into_deeplearning" data-v-aee51fed><meta property="position" content="4" data-v-aee51fed></li><li property="itemListElement" typeof="ListItem" data-v-aee51fed><a class="vp-link link breadcrumb" href="/blog/categories/?id=fea38a" property="item" typeof="WebPage" data-v-aee51fed><!--[-->循环神经网络<!--]--><!----></a><span class="vpi-chevron-right" data-v-aee51fed></span><meta property="name" content="循环神经网络" data-v-aee51fed><meta property="position" content="5" data-v-aee51fed></li><li property="itemListElement" typeof="ListItem" data-v-aee51fed><a class="vp-link link breadcrumb current" href="/learn/d2l/471b4f/" property="item" typeof="WebPage" data-v-aee51fed><!--[-->循环神经网络<!--]--><!----></a><!----><meta property="name" content="循环神经网络" data-v-aee51fed><meta property="position" content="6" data-v-aee51fed></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-bc6a6dcd><!----> 循环神经网络 <!----></h1><div class="vp-doc-meta" data-v-bc6a6dcd><!--[--><!--]--><p class="reading-time" data-v-bc6a6dcd><span class="vpi-books icon" data-v-bc6a6dcd></span><span data-v-bc6a6dcd>约 1021 字</span><span data-v-bc6a6dcd>大约 3 分钟</span></p><p data-v-bc6a6dcd><span class="vpi-tag icon" data-v-bc6a6dcd></span><!--[--><a class="vp-link link tag vp-tag-85d3" href="/blog/tags/?tag=RNN" data-v-bc6a6dcd><!--[-->RNN<!--]--><!----></a><!--]--></p><!--[--><!--]--><p class="create-time" data-v-bc6a6dcd><span class="vpi-clock icon" data-v-bc6a6dcd></span><span data-v-bc6a6dcd>2024-04-25</span></p></div><!--]--><!--[--><!--]--><div class="_learn_d2l_471b4f_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-15ae3a84><!--[--><!--]--><div data-v-15ae3a84><p>开始了文本方向的神经网络，之前的卷积看完还是很不知所云的， 对于为什么这样会更好还是只有一个大概的解释，估计文本这方面也不遑多让吧。</p><p>I have started learing language Models, but I&#39;m still confused after studying Convolutional Neural Networks. The explanations provided are quite vague, and I suspect Language Models might be just as challenging as CNNs</p><p>这一节从马可夫链开始，到一个简单的 RNN 实现结束，主要的难点还是在 RNN 实现方面的细节。</p><p>This section begins from Markov Chain, and concludes with a basic implementation of an RNN from scratch. The main challenge lies in the detailed of implementation of the RNN.</p><h2 id="循环神经网络从零开始实现-rnn-scratch" tabindex="-1"><a class="header-anchor" href="#循环神经网络从零开始实现-rnn-scratch"><span>循环神经网络从零开始实现 / rnn scratch</span></a></h2><h3 id="数据格式-data-format" tabindex="-1"><a class="header-anchor" href="#数据格式-data-format"><span>数据格式 / data format</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">train_iter</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> vocab </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> load_data_time_machine</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">batch_size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> num_steps</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><div class="hint-container note"><p class="hint-container-title">注</p><p>train_iter: 每次输出一个批量大小的 X 和 Y 。</p><p>train_iter: ouput a batch of X and Y with each iteration</p><p>X: tensor([[13, 14, 15, 16, 17], [28, 29, 30, 31, 32]])</p><p>Y: tensor([[14, 15, 16, 17, 18], [29, 30, 31, 32, 33]])</p><p>X: tensor([[ 3, 4, 5, 6, 7], [18, 19, 20, 21, 22]])</p><p>Y: tensor([[ 4, 5, 6, 7, 8], [19, 20, 21, 22, 23]])</p><p>X: tensor([[ 8, 9, 10, 11, 12], [23, 24, 25, 26, 27]])</p><p>Y: tensor([[ 9, 10, 11, 12, 13], [24, 25, 26, 27, 28]])</p></div><h3 id="为什么要对-x-进行转置-why-should-we-transpose-tensor-x" tabindex="-1"><a class="header-anchor" href="#为什么要对-x-进行转置-why-should-we-transpose-tensor-x"><span>为什么要对 X 进行转置 / why should we transpose tensor X</span></a></h3><p>首先需要知道的是本节所有的预测都是对<mark>字符</mark>的预测，所以 one_hot 的分类数是 28 。</p><p>Firstly, it is important to note that all predictions in this section are predictions of characters, so the number of class for the one-hot encoding is 28.</p><div class="hint-container note"><p class="hint-container-title">注</p><p>26 个英文字母 + 空格 + unk</p><p>26 English characters + space + unk</p></div><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">nn </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> functional </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">as</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> F</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">X </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> torch</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">arange</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">10</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">).</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">reshape</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">2</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 5</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">X</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ans </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> F</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">one_hot</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">X</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;"> 28</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ans</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">ans</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">shape</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>每次做的是对一个批量进行预测，所以每次我们取的是</p><p>Since our predictions are conducted on batches, our selection contain</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><annotation encoding="application/x-tex">\begin{bmatrix} 0&amp;1\\ 1&amp;2\\ 2&amp;3\\ \end{bmatrix} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:5.6em;"></span><span style="width:0.667em;height:3.600em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-1.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:5.6em;"></span><span style="width:0.667em;height:3.600em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>这里将X进行转置后相邻的批次读取的是<mark>时间</mark>上连续的，也就是文本顺序是正确的。</p><p>We transpose X to ensure that consecutive batches are read in time order, meaning the text sequence is pre preserved</p><h3 id="转置的好处-the-benefits-of-transposition" tabindex="-1"><a class="header-anchor" href="#转置的好处-the-benefits-of-transposition"><span>转置的好处 / the benefits of transposition</span></a></h3><p>其实就是一个行优先和列优先的问题，以及个人的习惯。</p><p>this a column provity or row proviet, and personal habbits this is actually a question of row priority versus column priority, as well as individual habits</p><p>python 是行优先的，所以每次批量读取转值后会带来 cache 命中的提升。</p><p>Python follows row priority, so each batch transpositon will result in improvement in cache hit rate</p><h2 id="torch-mm" tabindex="-1"><a class="header-anchor" href="#torch-mm"><span>torch.mm</span></a></h2><p>还是看GPT吧</p><p>torch.mm() 和 torch.matmul() 是 PyTorch 中用于执行矩阵乘法的两个函数，它们有一些区别：</p><h3 id="输入类型" tabindex="-1"><a class="header-anchor" href="#输入类型"><span>输入类型：</span></a></h3><p>torch.mm() 只能接受二维张量作为输入，即矩阵。</p><p>torch.matmul() 可以接受张量的任意维度作为输入，因此可以用于更广泛的矩阵乘法操作，包括批量矩阵乘法、广播等。</p><h3 id="广播规则" tabindex="-1"><a class="header-anchor" href="#广播规则"><span>广播规则：</span></a></h3><p>torch.mm() 对输入张量进行严格的形状匹配，要求两个输入张量的形状都是二维，并且第一个张量的列数必须等于第二个张量的行数。</p><p>torch.matmul() 则遵循广播规则，可以在满足一定条件的情况下，对具有不同形状的张量进行乘法操作。例如，可以对两个三维张量进行乘法，其中第一个张量的最后两个维度的形状必须与第二个张量的倒数两个维度的形状相匹配。</p><h3 id="支持批量矩阵乘法" tabindex="-1"><a class="header-anchor" href="#支持批量矩阵乘法"><span>支持批量矩阵乘法：</span></a></h3><p>torch.mm() 不支持批量矩阵乘法，即一次性处理多个矩阵乘积。</p><p>torch.matmul() 可以通过在输入张量的前面添加额外的维度来支持批量矩阵乘法，这在处理多个样本或批次数据时非常有用。</p><h2 id="有关-y-label" tabindex="-1"><a class="header-anchor" href="#有关-y-label"><span>有关 Y/label</span></a></h2><p>Y是一个 2x5 的 tensor ， rnn输出的是一个 10x28 的 tensor，这也就意味着 loss 那里要做一个 reshape。</p><h3 id="rnn-细节" tabindex="-1"><a class="header-anchor" href="#rnn-细节"><span>rnn 细节</span></a></h3><p>output 是一个 len 为 5 的 list 。list 里面为 torch.size(2,28) 的tensor。</p><p>对 list 进行 cat dim = 0 。</p></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-15ae3a84 data-v-11ad8f60><!--[--><!--]--><div class="edit-info" data-v-11ad8f60><div class="edit-link" data-v-11ad8f60><a class="vp-link link no-icon edit-link-button" href="https://github.com/shinonomeow/shinonomeow.top/edit/main/docs/learning_note/01.dive_into_deeplearning/08.循环神经网络/08.recurrent_neural_Network.md" target="_blank" rel="noreferrer" data-v-11ad8f60><!--[--><span class="vpi-square-pen edit-link-icon" aria-label="edit icon" data-v-11ad8f60></span> 编辑此页<!--]--><!----></a></div><!----></div><div class="contributors" aria-label="Contributors" data-v-11ad8f60><span class="contributors-label" data-v-11ad8f60>贡献者: </span><span class="contributors-info" data-v-11ad8f60><!--[--><!--[--><span class="contributor" data-v-11ad8f60>東雲柊</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-11ad8f60><div class="pager" data-v-11ad8f60><a class="vp-link link pager-link prev" href="/learn/d2l/670ae9/" data-v-11ad8f60><!--[--><span class="desc" data-v-11ad8f60>上一页</span><span class="title" data-v-11ad8f60>文本预处理</span><!--]--><!----></a></div><div class="pager" data-v-11ad8f60><a class="vp-link link pager-link next" href="/tools/f70e1a/" data-v-11ad8f60><!--[--><span class="desc" data-v-11ad8f60>下一页</span><span class="title" data-v-11ad8f60>docker</span><!--]--><!----></a></div></nav></footer><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;" data-v-15ae3a84><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-701fc3ad data-v-bacda9c1><span class="percent" data-allow-mismatch data-v-bacda9c1>0%</span><span class="show icon vpi-back-to-top" data-v-bacda9c1></span><svg aria-hidden="true" data-v-bacda9c1><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-bacda9c1></circle></svg></button><footer class="vp-footer" vp-footer data-v-701fc3ad data-v-5d4765e4><!--[--><div class="container" data-v-5d4765e4><p class="message" data-v-5d4765e4>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><!----></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-CN1iVX_s.js" defer></script></body></html>